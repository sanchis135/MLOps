{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5a39f09",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "The goal of this homework is to familiarize users with monitoring for ML batch services, using PostgreSQL database to store metrics and Grafana to visualize them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fa31bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from evidently import Report, Dataset, DataDefinition\n",
    "from evidently.presets import DataDriftPreset\n",
    "\n",
    "from joblib import load, dump\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3680cd",
   "metadata": {},
   "source": [
    "## Q1. Prepare the dataset\n",
    "\n",
    "Start with `baseline_model_nyc_taxi_data.ipynb`. Download the March 2024 Green Taxi data. We will use this data to simulate a production usage of a taxi trip duration prediction service.\n",
    "\n",
    "What is the shape of the downloaded data? How many rows are there?\n",
    "\n",
    "* 72044\n",
    "* 78537 \n",
    "* **57457**\n",
    "* 54396\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c344e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "green_tripdata_2024-03.parquet: 168it [00:00, 1324.94it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (57457, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "files = [('green_tripdata_2024-03.parquet', 'data')]\n",
    "\n",
    "for file, path in files:\n",
    "    url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/{file}\"\n",
    "    resp = requests.get(url, stream=True)\n",
    "    if resp.status_code != 200:\n",
    "        raise RuntimeError(f\"Error descargando {url}: status {resp.status_code}\")\n",
    "    save_path = os.path.join(path, file)\n",
    "    with open(save_path, \"wb\") as handle:\n",
    "        total = int(resp.headers.get(\"Content-Length\", 0))\n",
    "        for chunk in tqdm(resp.iter_content(chunk_size=8192),\n",
    "                          desc=file,\n",
    "                          total=total // 8192):\n",
    "            handle.write(chunk)\n",
    "\n",
    "march_data = pd.read_parquet('data/green_tripdata_2024-03.parquet')\n",
    "print(\"Shape:\", march_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fde8fc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57457 entries, 0 to 57456\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   VendorID               57457 non-null  int32         \n",
      " 1   lpep_pickup_datetime   57457 non-null  datetime64[us]\n",
      " 2   lpep_dropoff_datetime  57457 non-null  datetime64[us]\n",
      " 3   store_and_fwd_flag     55360 non-null  object        \n",
      " 4   RatecodeID             55360 non-null  float64       \n",
      " 5   PULocationID           57457 non-null  int32         \n",
      " 6   DOLocationID           57457 non-null  int32         \n",
      " 7   passenger_count        55360 non-null  float64       \n",
      " 8   trip_distance          57457 non-null  float64       \n",
      " 9   fare_amount            57457 non-null  float64       \n",
      " 10  extra                  57457 non-null  float64       \n",
      " 11  mta_tax                57457 non-null  float64       \n",
      " 12  tip_amount             57457 non-null  float64       \n",
      " 13  tolls_amount           57457 non-null  float64       \n",
      " 14  ehail_fee              0 non-null      float64       \n",
      " 15  improvement_surcharge  57457 non-null  float64       \n",
      " 16  total_amount           57457 non-null  float64       \n",
      " 17  payment_type           55360 non-null  float64       \n",
      " 18  trip_type              55353 non-null  float64       \n",
      " 19  congestion_surcharge   55360 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(14), int32(3), object(1)\n",
      "memory usage: 8.1+ MB\n"
     ]
    }
   ],
   "source": [
    "march_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da19181a",
   "metadata": {},
   "source": [
    "## Q2. Metric\n",
    "\n",
    "Let's expand the number of data quality metrics we’d like to monitor! Please add one metric of your choice and a quantile value for the `\"fare_amount\"` column (`quantile=0.5`).\n",
    "\n",
    "Hint: explore evidently metric `ColumnQuantileMetric` (from `evidently.metrics import ColumnQuantileMetric`) \n",
    "\n",
    "What metric did you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "544dbdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.8\n",
      "['_legacy', 'classification', 'column_statistics', 'dataset_statistics', 'group_by', 'recsys', 'regression', 'row_test_summary']\n"
     ]
    }
   ],
   "source": [
    "import evidently\n",
    "print(evidently.__version__)\n",
    "\n",
    "import pkgutil, evidently.metrics\n",
    "print([m.name for m in pkgutil.iter_modules(evidently.metrics.__path__)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4509641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.metrics.column_statistics import QuantileValue\n",
    "\n",
    "metric = QuantileValue(column=\"fare_amount\", quantile=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37aecfd",
   "metadata": {},
   "source": [
    "## Q3. Monitoring\n",
    "\n",
    "Let’s start monitoring. Run expanded monitoring for a new batch of data (March 2024). \n",
    "\n",
    "What is the maximum value of metric `quantile = 0.5` on the `\"fare_amount\"` column during March 2024 (calculated daily)?\n",
    "\n",
    "* 10\n",
    "* 12.5\n",
    "* **14.2**\n",
    "* 14.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e031426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum daily median of 'fare_amount' in March 2024 is: 14.2\n"
     ]
    }
   ],
   "source": [
    "# Ensure the 'lpep_pickup_datetime' column is in datetime format\n",
    "march_data['lpep_pickup_datetime'] = pd.to_datetime(march_data['lpep_pickup_datetime'])\n",
    "\n",
    "# Filter data for March 2024\n",
    "df_march = march_data[(march_data['lpep_pickup_datetime'].dt.month == 3) & (march_data['lpep_pickup_datetime'].dt.year == 2024)]\n",
    "\n",
    "# Extract the date without the time\n",
    "df_march['pickup_date'] = df_march['lpep_pickup_datetime'].dt.date\n",
    "\n",
    "# Calculate the daily median of 'fare_amount'\n",
    "daily_median = df_march.groupby('pickup_date')['fare_amount'].median()\n",
    "\n",
    "# Get the maximum of the daily medians\n",
    "max_daily_median = daily_median.max()\n",
    "\n",
    "print(f\"The maximum daily median of 'fare_amount' in March 2024 is: {max_daily_median}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea2884c",
   "metadata": {},
   "source": [
    "## Q4. Dashboard\n",
    "\n",
    "\n",
    "Finally, let’s add panels with new added metrics to the dashboard. After we customize the  dashboard let's save a dashboard config, so that we can access it later. Hint: click on “Save dashboard” to access JSON configuration of the dashboard. This configuration should be saved locally.\n",
    "\n",
    "Where to place a dashboard config file?\n",
    "\n",
    "* `project_folder` (05-monitoring)\n",
    "* `project_folder/config`  (05-monitoring/config)\n",
    "* **`project_folder/dashboards`  (05-monitoring/dashboards)**\n",
    "* `project_folder/data`  (05-monitoring/data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b401a6",
   "metadata": {},
   "source": [
    "Assume the following directory structure (pgsql): \n",
    "\n",
    "05-monitoring/\n",
    "├── dashboards/\n",
    "│   └── fare_dashboard.json\n",
    "└── provisioning/\n",
    "    └── dashboards/\n",
    "        └── dashboard.yaml\n",
    "fare_dashboard.json: Contains the JSON definition of your dashboard.\n",
    "\n",
    "dashboard.yaml: Configuration file that tells Grafana where to find the dashboard JSON files.\n",
    "\n",
    "**Step 1:** Create the Dashboard in Grafana (grafana.com)\n",
    "- Log in to your Grafana instance.\n",
    "- Create a new dashboard with the desired panels.\n",
    "- Click on the gear icon (⚙️) at the top of the dashboard and select \"JSON Model\".\n",
    "- Copy the JSON content displayed.\n",
    "- Paste this content into fare_dashboard.json located in the dashboards/ folder.\n",
    "\n",
    "**Step 2:** Configure File Provisioning in Grafana\n",
    "- Locate your Grafana configuration file, typically named grafana.ini.\n",
    "- Enable the required feature toggles:\n",
    "[feature_toggles]\n",
    "provisioning = true\n",
    "kubernetesDashboards = true ; use k8s from browser\n",
    "- Configure the permitted provisioning paths:\n",
    "[paths]\n",
    "permitted_provisioning_paths = /etc/grafana/provisioning/dashboards\n",
    "Restart Grafana to apply the changes.\n",
    "\n",
    "**Step 3:** Create the Dashboard Configuration File\n",
    "In the provisioning/dashboards/ directory, create a file named dashboard.yaml with the following content (yaml):\n",
    "apiVersion: 1\n",
    "\n",
    "providers:\n",
    "  - name: 'Fare Dashboard Provider'\n",
    "    folder: 'Fare Dashboards'\n",
    "    type: 'file'\n",
    "    options:\n",
    "      path: '/etc/grafana/provisioning/dashboards/dashboards/'\n",
    "name: A unique name for the provider.\n",
    "\n",
    "folder: The folder in Grafana where the dashboards will appear.\n",
    "\n",
    "type: Set to 'file' to load dashboards from files.\n",
    "\n",
    "options.path: The path to the directory containing the dashboard JSON files.\n",
    "medium.com\n",
    "\n",
    "**Step 4:** Verify the Dashboard in Grafana\n",
    "- Restart Grafana if you haven't already. \n",
    "- Navigate to Dashboards > Manage in the Grafana sidebar.\n",
    "- You should see a folder named \"Fare Dashboards\" containing your provisioned dashboard.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
